# Exemples de configurations de stockage réseau sécurisé
# NFS, iSCSI et autres backends de stockage réseau

---
# Exemple 1: PersistentVolume NFS avec options de sécurité
# Use case: Partage de fichiers statiques entre plusieurs pods
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-shared-assets-pv
  labels:
    type: nfs
    tier: shared-storage
    environment: production
spec:
  capacity:
    storage: 100Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany  # Plusieurs pods peuvent lire/écrire simultanément
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs-shared-secure
  mountOptions:
    # Options de sécurité et performance NFS
    - nfsvers=4.1       # Version NFSv4.1 minimum (support Kerberos)
    - hard              # Mode hard: réessayer en cas d'échec réseau
    - intr              # Interruptible par signal
    - noatime           # Ne pas mettre à jour access time (performance)
    - nodiratime        # Ne pas mettre à jour directory access time
    - rsize=1048576     # Read size: 1MB
    - wsize=1048576     # Write size: 1MB
    - timeo=600         # Timeout: 60 secondes
    - retrans=2         # Nombre de retransmissions avant erreur
    - sec=sys           # Sécurité: sys (remplacer par krb5 si Kerberos disponible)
  nfs:
    server: nfs-server.internal.company.com
    path: "/exports/kubernetes/shared-assets"

---
# PVC pour consommer le PV NFS
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-shared-assets-pvc
  namespace: production
  labels:
    app: web-assets
spec:
  storageClassName: nfs-shared-secure
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 50Gi
  selector:
    matchLabels:
      type: nfs
      tier: shared-storage

---
# Deployment utilisant le NFS partagé pour des assets web
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-frontend
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-frontend
  template:
    metadata:
      labels:
        app: web-frontend
        access-nfs: "true"  # Pour NetworkPolicy
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 2000
        fsGroupChangePolicy: "OnRootMismatch"
      containers:
      - name: nginx
        image: nginx:1.25-alpine
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: shared-assets
          mountPath: /usr/share/nginx/html/assets
          readOnly: true  # Lecture seule pour les frontends
        - name: cache
          mountPath: /var/cache/nginx
        - name: tmp
          mountPath: /tmp
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: shared-assets
        persistentVolumeClaim:
          claimName: nfs-shared-assets-pvc
      - name: cache
        emptyDir:
          sizeLimit: 100Mi
      - name: tmp
        emptyDir:
          sizeLimit: 50Mi

---
# NetworkPolicy pour restreindre l'accès au serveur NFS
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: nfs-server-access-policy
  namespace: storage-system
spec:
  podSelector:
    matchLabels:
      app: nfs-server
  policyTypes:
  - Ingress
  ingress:
  # Autoriser uniquement les pods avec le label access-nfs: "true"
  - from:
    - podSelector:
        matchLabels:
          access-nfs: "true"
    - namespaceSelector:
        matchLabels:
          nfs-access: "allowed"
    ports:
    - protocol: TCP
      port: 2049  # NFS
    - protocol: TCP
      port: 111   # RPC portmapper
    - protocol: UDP
      port: 111

---
# Exemple 2: iSCSI PersistentVolume avec authentification CHAP
# Use case: Stockage block haute performance pour base de données
apiVersion: v1
kind: Secret
metadata:
  name: iscsi-chap-secret
  namespace: production
type: kubernetes.io/iscsi-chap
stringData:
  # Credentials CHAP pour l'authentification iSCSI
  # ⚠️ En production, utiliser un gestionnaire de secrets
  node.session.auth.username: "iscsi-initiator-user"
  node.session.auth.password: "SecurePassword!2024"
  # Pour mutual CHAP (optionnel mais recommandé)
  node.session.auth.username_in: "iscsi-target-user"
  node.session.auth.password_in: "SecureTargetPassword!2024"

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: iscsi-database-pv
  labels:
    type: iscsi
    performance: high
    tier: database
spec:
  capacity:
    storage: 500Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce  # iSCSI est généralement RWO
  persistentVolumeReclaimPolicy: Retain
  storageClassName: iscsi-fast
  iscsi:
    targetPortal: 192.168.10.100:3260
    iqn: iqn.2024-01.com.company.storage:lun.database01
    lun: 1
    fsType: ext4
    readOnly: false
    # Authentification CHAP
    chapAuthDiscovery: true
    chapAuthSession: true
    secretRef:
      name: iscsi-chap-secret
    # Options iSCSI
    portals:
      - '192.168.10.101:3260'  # Portal secondaire pour HA
      - '192.168.10.102:3260'  # Portal tertiaire

---
# PVC pour le volume iSCSI
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: iscsi-database-pvc
  namespace: production
spec:
  storageClassName: iscsi-fast
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
  selector:
    matchLabels:
      type: iscsi
      tier: database

---
# Exemple 3: Ceph RBD avec chiffrement
# Use case: Stockage distribué on-premise
apiVersion: v1
kind: Secret
metadata:
  name: ceph-secret
  namespace: production
type: kubernetes.io/rbd
stringData:
  # Clé d'authentification Ceph
  key: AQD1h3xeK7fXBBAA8+A6h8QmZJ3K7j8F9x+8Yw==

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ceph-rbd-pv
  labels:
    type: ceph-rbd
    tier: distributed-storage
spec:
  capacity:
    storage: 1Ti
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ceph-rbd-encrypted
  rbd:
    monitors:
      - 192.168.10.10:6789
      - 192.168.10.11:6789
      - 192.168.10.12:6789
    pool: kubernetes
    image: pv-data-001
    fsType: ext4
    readOnly: false
    user: kubernetes
    secretRef:
      name: ceph-secret

---
# Exemple 4: Pod avec multiple types de stockage (best practices)
apiVersion: v1
kind: Pod
metadata:
  name: multi-storage-app
  namespace: production
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault

  containers:
  - name: app
    image: myapp:1.0.0
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true

    volumeMounts:
    # Volume persistant pour les données importantes
    - name: data
      mountPath: /app/data
      readOnly: false

    # Volume NFS partagé pour les assets
    - name: shared-assets
      mountPath: /app/assets
      readOnly: true

    # Volume pour les fichiers de configuration
    - name: config
      mountPath: /app/config
      readOnly: true

    # Volume pour les secrets
    - name: secrets
      mountPath: /app/secrets
      readOnly: true

    # Volumes temporaires
    - name: tmp
      mountPath: /tmp
    - name: cache
      mountPath: /app/cache

    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "500m"

  volumes:
  # PVC pour données persistantes (peut être iSCSI, Ceph, EBS, etc.)
  - name: data
    persistentVolumeClaim:
      claimName: app-data-pvc

  # PVC NFS pour assets partagés
  - name: shared-assets
    persistentVolumeClaim:
      claimName: nfs-shared-assets-pvc

  # ConfigMap pour configuration
  - name: config
    configMap:
      name: app-config
      defaultMode: 0440  # r--r-----

  # Secret pour credentials
  - name: secrets
    secret:
      secretName: app-secrets
      defaultMode: 0400  # r--------

  # emptyDir pour fichiers temporaires
  - name: tmp
    emptyDir:
      sizeLimit: 500Mi

  # emptyDir en RAM pour cache
  - name: cache
    emptyDir:
      medium: Memory
      sizeLimit: 256Mi

---
# Exemple 5: NFS Server déployé dans Kubernetes (pour dev/test)
# ⚠️ NON RECOMMANDÉ pour production - utiliser un NFS externe dédié
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-server-storage
  namespace: storage-system
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 200Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-server
  namespace: storage-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-server
  template:
    metadata:
      labels:
        app: nfs-server
    spec:
      securityContext:
        runAsNonRoot: false  # NFS server nécessite root (limitation)
        fsGroup: 65534
      containers:
      - name: nfs-server
        image: k8s.gcr.io/volume-nfs:0.8
        ports:
        - name: nfs
          containerPort: 2049
        - name: mountd
          containerPort: 20048
        - name: rpcbind
          containerPort: 111
        securityContext:
          privileged: true  # Nécessaire pour NFS server
          capabilities:
            add:
            - SYS_ADMIN
            - SETPCAP
        volumeMounts:
        - name: storage
          mountPath: /exports
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: nfs-server-storage

---
apiVersion: v1
kind: Service
metadata:
  name: nfs-server
  namespace: storage-system
spec:
  selector:
    app: nfs-server
  ports:
  - name: nfs
    port: 2049
  - name: mountd
    port: 20048
  - name: rpcbind
    port: 111
  clusterIP: 10.96.0.100  # IP fixe pour faciliter la configuration

---
# Exemple 6: StatefulSet avec stockage pour chaque replica
# Use case: Cluster de bases de données (Cassandra, MongoDB, etc.)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database-cluster
  namespace: production
spec:
  serviceName: database-cluster
  replicas: 3
  selector:
    matchLabels:
      app: database-cluster
  template:
    metadata:
      labels:
        app: database-cluster
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 999
        fsGroup: 999
        fsGroupChangePolicy: "OnRootMismatch"
      containers:
      - name: database
        image: cassandra:4.1
        ports:
        - containerPort: 9042
          name: cql
        volumeMounts:
        - name: data
          mountPath: /var/lib/cassandra
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"

  # VolumeClaimTemplates: crée un PVC par replica
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: database-cluster
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: database-with-snapshots
      resources:
        requests:
          storage: 100Gi

---
# Headless Service pour le StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: database-cluster
  namespace: production
spec:
  selector:
    app: database-cluster
  ports:
  - port: 9042
    name: cql
  clusterIP: None  # Headless

---
# Exemple 7: Backup Job pour sauvegarder les données vers S3
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
  namespace: production
spec:
  schedule: "0 2 * * *"  # Tous les jours à 2h du matin
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 2000
          containers:
          - name: backup
            image: amazon/aws-cli:2.13.0
            command:
            - /bin/sh
            - -c
            - |
              # Créer un snapshot du volume
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              tar czf /tmp/backup-${TIMESTAMP}.tar.gz /data

              # Uploader vers S3
              aws s3 cp /tmp/backup-${TIMESTAMP}.tar.gz \
                s3://my-backups-bucket/database/backup-${TIMESTAMP}.tar.gz \
                --storage-class STANDARD_IA

              # Nettoyer
              rm /tmp/backup-${TIMESTAMP}.tar.gz

              echo "Backup completed: backup-${TIMESTAMP}.tar.gz"

            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
            - name: AWS_DEFAULT_REGION
              value: "us-east-1"

            volumeMounts:
            - name: data
              mountPath: /data
              readOnly: true
            - name: tmp
              mountPath: /tmp

            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                - ALL
              readOnlyRootFilesystem: true

            resources:
              requests:
                memory: "256Mi"
                cpu: "200m"
              limits:
                memory: "512Mi"
                cpu: "500m"

          volumes:
          - name: data
            persistentVolumeClaim:
              claimName: iscsi-database-pvc
          - name: tmp
            emptyDir:
              sizeLimit: 10Gi
