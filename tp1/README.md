# TP1 - Premier dÃ©ploiement Kubernetes sur AlmaLinux

> **ğŸ’» Utilisateurs Windows :** Consultez le [guide spÃ©cifique Windows (WINDOWS.md)](WINDOWS.md) qui adapte ce TP pour Windows avec Minikube ou WSL2. Voir aussi le [guide d'installation Windows complet](../docs/WINDOWS_SETUP.md).

## Objectifs du TP

Ã€ la fin de ce TP, vous serez capable de :
- Installer et configurer un cluster Kubernetes (minikube ou kubeadm)
- DÃ©marrer un cluster Kubernetes
- DÃ©ployer votre premiÃ¨re application
- Exposer l'application via un service
- Interagir avec les pods et services

## PrÃ©requis

### Pour minikube (dÃ©veloppement local)
- Une machine AlmaLinux (physique ou virtuelle) **ou Windows** ([voir guide Windows](WINDOWS.md))
- 2 CPU minimum (4 CPU recommandÃ© pour Windows)
- 2 Go de RAM minimum (4 Go recommandÃ© pour Windows)
- 20 Go d'espace disque
- AccÃ¨s root ou sudo (ou droits administrateur sur Windows)

### Pour kubeadm (environnement multi-nÅ“uds)
- 2-3 machines AlmaLinux (1 master + 1-2 workers) **ou WSL2 sur Windows**
- **Master :** 2 CPU, 2 Go RAM, 20 Go disque
- **Workers :** 1 CPU, 1 Go RAM, 20 Go disque
- RÃ©seau entre les machines
- AccÃ¨s root ou sudo

## Choix de votre environnement

Ce TP peut Ãªtre rÃ©alisÃ© avec **deux approches diffÃ©rentes** :

### Option A : minikube (recommandÃ© pour dÃ©buter)
- âœ… Installation rapide et simple
- âœ… IdÃ©al pour le dÃ©veloppement local
- âœ… NÃ©cessite une seule machine
- âœ… Gestion automatique du rÃ©seau
- âŒ Ne reflÃ¨te pas un environnement de production
- âŒ Limitations pour le multi-nÅ“ud

### Option B : kubeadm (recommandÃ© pour la production)
- âœ… Architecture rÃ©aliste multi-nÅ“uds
- âœ… Proche d'un environnement de production
- âœ… ContrÃ´le total sur la configuration
- âœ… ScalabilitÃ© native
- âŒ Installation plus complexe
- âŒ NÃ©cessite plusieurs machines

**ğŸ’¡ Conseil :** Commencez avec minikube pour apprendre les concepts, puis passez Ã  kubeadm pour comprendre la production.

---

## Partie 1 : Installation de l'environnement

### 1.1 Mise Ã  jour du systÃ¨me

```bash
sudo dnf update -y
```

### 1.2 Installation de Docker

```bash
# Installer les dÃ©pendances
sudo dnf install -y yum-utils device-mapper-persistent-data lvm2

# Ajouter le repository Docker
sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# Installer Docker
sudo dnf install -y docker-ce docker-ce-cli containerd.io

# DÃ©marrer et activer Docker
sudo systemctl start docker
sudo systemctl enable docker

# Ajouter votre utilisateur au groupe docker
sudo usermod -aG docker $USER

# Appliquer les changements (ou se reconnecter)
newgrp docker
```

### 1.3 Installation de kubectl

```bash
# TÃ©lÃ©charger kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

# Rendre le binaire exÃ©cutable
chmod +x kubectl

# DÃ©placer vers /usr/local/bin
sudo mv kubectl /usr/local/bin/

# VÃ©rifier l'installation
kubectl version --client
```

### 1.4 Installation de minikube (Option A)

**Si vous choisissez minikube :**

```bash
# TÃ©lÃ©charger minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

# Installer minikube
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# VÃ©rifier l'installation
minikube version
```

### 1.5 Installation de kubeadm (Option B)

**Si vous choisissez kubeadm :**

Pour une installation complÃ¨te avec kubeadm, consultez le **[Guide d'installation kubeadm](../docs/KUBEADM_SETUP.md)** qui couvre :
- La prÃ©paration des nÅ“uds (dÃ©sactivation swap, modules kernel, etc.)
- L'installation de containerd
- L'installation de kubeadm, kubelet et kubectl
- L'initialisation du cluster
- L'ajout de workers
- La configuration du rÃ©seau (CNI)

**Installation rapide (rÃ©sumÃ©) :**

```bash
# Sur TOUS les nÅ“uds (master et workers)

# 1. DÃ©sactiver swap et SELinux
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# 2. Configurer les modules kernel
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system

# 3. Installer containerd
sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo dnf install -y containerd.io
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd

# 4. Installer kubeadm, kubelet et kubectl
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF

sudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
sudo systemctl enable --now kubelet
```

**Sur le nÅ“ud MASTER uniquement :**

```bash
# Initialiser le cluster
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# Configurer kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Installer Flannel (CNI)
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
```

**Sur chaque nÅ“ud WORKER :**

```bash
# Utiliser la commande 'kubeadm join' affichÃ©e aprÃ¨s l'init sur le master
# Exemple :
# sudo kubeadm join <master-ip>:6443 --token <token> \
#   --discovery-token-ca-cert-hash sha256:<hash>
```

**ğŸ’¡ Note :** Consultez le [guide complet kubeadm](../docs/KUBEADM_SETUP.md) pour plus de dÃ©tails et le dÃ©pannage.

---

## Partie 2 : DÃ©marrage du cluster Kubernetes

### 2.1 Option A : DÃ©marrer minikube

**Si vous utilisez minikube :**

```bash
# DÃ©marrer minikube avec Docker comme driver
minikube start --driver=docker

# VÃ©rifier le statut
minikube status
```

**RÃ©sultat attendu :**
```
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

### 2.1 Option B : VÃ©rifier le cluster kubeadm

**Si vous utilisez kubeadm :**

AprÃ¨s avoir suivi les Ã©tapes d'installation de la section 1.5, vÃ©rifiez que votre cluster est opÃ©rationnel :

```bash
# VÃ©rifier que tous les pods systÃ¨me sont prÃªts
kubectl get pods -n kube-system

# Attendre que tous les pods soient Running
kubectl wait --for=condition=ready pod --all -n kube-system --timeout=300s
```

**RÃ©sultat attendu :** Tous les pods (coredns, flannel, kube-proxy, etc.) doivent Ãªtre en Ã©tat `Running`.

### 2.2 VÃ©rifier le cluster

**Ces commandes fonctionnent pour minikube ET kubeadm :**

```bash
# Afficher les informations du cluster
kubectl cluster-info

# Lister les nÅ“uds
kubectl get nodes

# Afficher plus de dÃ©tails sur les nÅ“uds
kubectl describe nodes
```

**Avec minikube, vous verrez :**
```
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   5m    v1.29.0
```

**Avec kubeadm (exemple 1 master + 2 workers), vous verrez :**
```
NAME              STATUS   ROLES           AGE   VERSION
master-node       Ready    control-plane   10m   v1.29.0
worker-node-1     Ready    <none>          5m    v1.29.0
worker-node-2     Ready    <none>          4m    v1.29.0
```

## Partie 3 : Premier dÃ©ploiement

### 3.1 DÃ©ployer une application Nginx

```bash
# CrÃ©er un dÃ©ploiement nginx
kubectl create deployment nginx-demo --image=nginx:latest

# VÃ©rifier le dÃ©ploiement
kubectl get deployments

# VÃ©rifier les pods
kubectl get pods
```

### 3.2 Examiner le pod

```bash
# Obtenir plus d'informations sur le pod
kubectl get pods -o wide

# DÃ©crire le pod (remplacer <pod-name> par le nom rÃ©el)
kubectl describe pod <pod-name>

# Voir les logs du pod
kubectl logs <pod-name>
```

## Partie 4 : Comprendre les types de Service Kubernetes

Avant d'exposer notre application, il est important de comprendre les diffÃ©rents types de services disponibles dans Kubernetes. Un **Service** est une abstraction qui dÃ©finit un ensemble logique de pods et une politique d'accÃ¨s Ã  ces pods.

### 4.1 Les trois types de Service principaux

#### ClusterIP (par dÃ©faut)

**Description :** Expose le service sur une IP interne au cluster. Ce type rend le service accessible uniquement depuis l'intÃ©rieur du cluster Kubernetes.

**Cas d'usage :**
- Communication entre services internes (ex: backend vers base de donnÃ©es)
- Services qui ne doivent pas Ãªtre accessibles depuis l'extÃ©rieur
- Micro-services communiquant entre eux

**Exemple :**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-internal-service
spec:
  type: ClusterIP  # Peut Ãªtre omis car c'est la valeur par dÃ©faut
  selector:
    app: my-app
  ports:
  - protocol: TCP
    port: 80          # Port du service
    targetPort: 8080  # Port du conteneur
```

**SchÃ©ma conceptuel :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Cluster Kubernetes          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Pod A   â”‚â”€â”€â”€â”€â”€â–¶â”‚ Service  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ClusterIP â”‚   â”‚
â”‚                    â”‚ 10.0.0.5 â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  Pod B   â”‚â”€â”€â”€â”€â”€â–¶      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â–¼         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                    â”‚  Pods    â”‚    â”‚
â”‚                    â”‚  Backend â”‚    â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### NodePort

**Description :** Expose le service sur un port statique de chaque nÅ“ud du cluster. Kubernetes alloue automatiquement un port dans la plage 30000-32767 (configurable). Le service devient accessible depuis l'extÃ©rieur via `<NodeIP>:<NodePort>`.

**Cas d'usage :**
- Environnements de dÃ©veloppement/test (comme minikube)
- Applications qui doivent Ãªtre accessibles depuis l'extÃ©rieur sans load balancer
- AccÃ¨s direct pour le dÃ©bogage

**Exemple :**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-nodeport-service
spec:
  type: NodePort
  selector:
    app: my-app
  ports:
  - protocol: TCP
    port: 80           # Port du service
    targetPort: 8080   # Port du conteneur
    nodePort: 30080    # Port sur chaque nÅ“ud (optionnel, sinon auto-assignÃ©)
```

**SchÃ©ma conceptuel :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Cluster Kubernetes            â”‚
â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Node     â”‚    â”‚ Service  â”‚      â”‚
â”‚  â”‚192.168.1.10â”‚    â”‚ NodePort â”‚      â”‚
â”‚  â”‚Port: 30080 â”‚â—€â”€â”€â”€â”‚          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                       â”‚  Pods    â”‚   â”‚
â”‚                       â”‚  Backend â”‚   â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Client â”‚ accÃ¨de via http://192.168.1.10:30080
    â”‚Externe â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### LoadBalancer

**Description :** Expose le service via un load balancer externe fourni par le cloud provider (AWS ELB, GCP Load Balancer, Azure Load Balancer, etc.). C'est une extension du type NodePort : un service LoadBalancer crÃ©e automatiquement un NodePort et demande au cloud provider de crÃ©er un load balancer pointant vers ce NodePort.

**Cas d'usage :**
- Applications en production sur des plateformes cloud
- Services qui nÃ©cessitent une IP publique stable
- Distribution automatique du trafic avec haute disponibilitÃ©

**Exemple :**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-loadbalancer-service
spec:
  type: LoadBalancer
  selector:
    app: my-app
  ports:
  - protocol: TCP
    port: 80           # Port du load balancer
    targetPort: 8080   # Port du conteneur
```

**SchÃ©ma conceptuel :**
```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Client â”‚
    â”‚Internetâ”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Balancer   â”‚  â—€â”€â”€â”€ IP Publique: 203.0.113.10
â”‚  (Cloud Provider)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Cluster Kubernetes             â”‚
â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Nodes    â”‚    â”‚ Service  â”‚      â”‚
â”‚  â”‚:30080-32767â”‚â—€â”€â”€â”€â”‚LoadBal.  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                       â”‚  Pods    â”‚   â”‚
â”‚                       â”‚  Backend â”‚   â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Note sur minikube :** Dans un environnement minikube (cluster local), le type LoadBalancer sera automatiquement converti en NodePort car il n'y a pas de cloud provider pour crÃ©er un vrai load balancer. Minikube fournit la commande `minikube tunnel` pour simuler un load balancer en environnement local.

### 4.2 Tableau comparatif

| Type | Accessible depuis | IP externe | Cas d'usage principal | Port Range |
|------|-------------------|------------|----------------------|------------|
| **ClusterIP** | Cluster uniquement | Non | Services internes | Port du service (ex: 80, 3306) |
| **NodePort** | Externe (NodeIP:Port) | Non | Dev/Test, accÃ¨s direct | 30000-32767 |
| **LoadBalancer** | Externe (via LB) | Oui | Production cloud | Standard (80, 443, etc.) |

### 4.3 Comment choisir le bon type ?

```
Besoin d'accÃ¨s externe ?
â”‚
â”œâ”€ NON  â”€â”€â–¶ ClusterIP
â”‚           (communication interne)
â”‚
â””â”€ OUI
    â”‚
    â”œâ”€ Environnement local/dev ?
    â”‚  OUI â”€â”€â–¶ NodePort
    â”‚          (accÃ¨s via IP:Port du nÅ“ud)
    â”‚
    â””â”€ NON (Production cloud)
       â””â”€â”€â–¶ LoadBalancer
            (IP publique + distribution)
```

## Partie 5 : Exposition de l'application

### 5.1 CrÃ©er un service

```bash
# Exposer le dÃ©ploiement via un service de type NodePort
kubectl expose deployment nginx-demo --type=NodePort --port=80

# VÃ©rifier le service
kubectl get services
```

**Note :** Nous utilisons NodePort ici car minikube est un environnement local. Pour comprendre quand utiliser NodePort vs ClusterIP vs LoadBalancer, rÃ©fÃ©rez-vous Ã  la section 4 ci-dessus.

### 5.2 AccÃ©der Ã  l'application

#### Option A : Avec minikube

```bash
# Obtenir l'URL du service
minikube service nginx-demo --url

# Ou ouvrir directement dans le navigateur
minikube service nginx-demo
```

**Alternative avec curl :**
```bash
# RÃ©cupÃ©rer l'IP et le port
export NODE_PORT=$(kubectl get services nginx-demo -o jsonpath='{.spec.ports[0].nodePort}')
export NODE_IP=$(minikube ip)

# Tester l'accÃ¨s
curl http://$NODE_IP:$NODE_PORT
```

#### Option B : Avec kubeadm

Avec kubeadm, vous accÃ©dez au service via l'IP de n'importe quel nÅ“ud et le NodePort :

```bash
# RÃ©cupÃ©rer le NodePort assignÃ©
export NODE_PORT=$(kubectl get services nginx-demo -o jsonpath='{.spec.ports[0].nodePort}')

# RÃ©cupÃ©rer l'IP d'un worker (ou du master si scheduling autorisÃ©)
export NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')

# Afficher l'URL
echo "Service accessible Ã  : http://$NODE_IP:$NODE_PORT"

# Tester l'accÃ¨s
curl http://$NODE_IP:$NODE_PORT
```

**Note :** Avec kubeadm en multi-nÅ“uds, le service est accessible via **n'importe quel nÅ“ud** du cluster grÃ¢ce Ã  kube-proxy, mÃªme si le pod n'est pas sur ce nÅ“ud.

**Astuce :** Pour un accÃ¨s plus simple en production, considÃ©rez :
- **Ingress Controller** : Pour le routage HTTP/HTTPS (voir TPs suivants)
- **MetalLB** : Pour des LoadBalancers avec IP externe (voir [guide kubeadm](../docs/KUBEADM_SETUP.md#partie-6--configuration-du-loadbalancer-metallb))
- **HAProxy/Nginx externe** : Pour load balancer devant les NodePorts

## Partie 6 : Manipulation avancÃ©e

### 6.1 Scaler l'application

```bash
# Augmenter le nombre de rÃ©plicas Ã  3
kubectl scale deployment nginx-demo --replicas=3

# VÃ©rifier les pods
kubectl get pods

# Observer la distribution
kubectl get pods -o wide
```

### 6.2 Mettre Ã  jour l'application

```bash
# Mettre Ã  jour l'image vers une version spÃ©cifique
kubectl set image deployment/nginx-demo nginx=nginx:1.24

# Suivre le rollout
kubectl rollout status deployment/nginx-demo

# Voir l'historique des dÃ©ploiements
kubectl rollout history deployment/nginx-demo
```

### 6.3 Revenir Ã  la version prÃ©cÃ©dente

```bash
# Annuler le dernier dÃ©ploiement
kubectl rollout undo deployment/nginx-demo

# VÃ©rifier le statut
kubectl rollout status deployment/nginx-demo
```

## Partie 7 : Utilisation de fichiers YAML

### 7.1 CrÃ©er un fichier de dÃ©ploiement

CrÃ©er un fichier `webapp-deployment.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  labels:
    app: webapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: httpd:2.4
        ports:
        - containerPort: 80
```

### 7.2 CrÃ©er un fichier de service

CrÃ©er un fichier `webapp-service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
spec:
  type: NodePort
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080
```

**Note :** Ce service utilise un NodePort fixe (30080) ce qui est pratique pour le dÃ©veloppement. Consultez la Partie 4 pour comprendre quand utiliser ce type de service.

### 7.3 Appliquer les configurations

```bash
# Appliquer le dÃ©ploiement
kubectl apply -f webapp-deployment.yaml

# Appliquer le service
kubectl apply -f webapp-service.yaml

# VÃ©rifier les ressources crÃ©Ã©es
kubectl get deployments,services,pods
```

### 7.4 Tester l'application

#### Option A : Avec minikube

```bash
# AccÃ©der au service
curl http://$(minikube ip):30080
```

#### Option B : Avec kubeadm

```bash
# RÃ©cupÃ©rer l'IP d'un nÅ“ud
export NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')

# Tester l'accÃ¨s
curl http://$NODE_IP:30080

# Ou depuis un autre serveur sur le rÃ©seau
# curl http://<IP-du-noeud>:30080
```

**Note :** Avec kubeadm, le service est accessible sur le port 30080 depuis n'importe quel nÅ“ud du cluster grÃ¢ce Ã  kube-proxy.

## Partie 8 : Nettoyage et commandes utiles

### 8.1 Nettoyer les ressources

```bash
# Supprimer le dÃ©ploiement nginx-demo
kubectl delete deployment nginx-demo
kubectl delete service nginx-demo

# Supprimer les ressources webapp
kubectl delete -f webapp-deployment.yaml
kubectl delete -f webapp-service.yaml

# Ou supprimer par nom
kubectl delete deployment webapp
kubectl delete service webapp-service
```

### 8.2 Commandes utiles

#### Communes (minikube et kubeadm)

```bash
# Voir toutes les ressources dans le namespace par dÃ©faut
kubectl get all

# Voir les pods de tous les namespaces
kubectl get pods --all-namespaces

# Afficher les Ã©vÃ©nements rÃ©cents
kubectl get events --sort-by='.lastTimestamp'
```

#### SpÃ©cifiques minikube

```bash
# AccÃ©der au dashboard Kubernetes
minikube dashboard

# Voir les addons disponibles
minikube addons list

# Activer un addon (exemple: metrics-server)
minikube addons enable metrics-server

# Voir les logs de minikube
minikube logs

# SSH dans le nÅ“ud minikube
minikube ssh
```

#### SpÃ©cifiques kubeadm

```bash
# Installer le dashboard manuellement
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

# CrÃ©er un token pour accÃ©der au dashboard
kubectl -n kubernetes-dashboard create token admin-user

# AccÃ©der au dashboard via port-forward
kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8443:443

# Installer metrics-server manuellement
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# SSH dans un nÅ“ud spÃ©cifique (adapter l'IP)
ssh user@<node-ip>

# Voir les logs des composants systÃ¨me
kubectl logs -n kube-system -l component=kube-apiserver
kubectl logs -n kube-system -l k8s-app=kube-proxy
```

### 8.3 ArrÃªter et supprimer le cluster

#### Avec minikube

```bash
# ArrÃªter minikube
minikube stop

# Supprimer le cluster
minikube delete

# DÃ©marrer Ã  nouveau
minikube start
```

#### Avec kubeadm

```bash
# Pour arrÃªter le cluster, arrÃªter les VMs/serveurs ou :
# Sur chaque nÅ“ud
sudo systemctl stop kubelet

# Pour redÃ©marrer
sudo systemctl start kubelet

# Pour supprimer complÃ¨tement le cluster
# Sur tous les nÅ“uds (master et workers)
sudo kubeadm reset -f
sudo rm -rf /etc/cni/net.d
sudo rm -rf $HOME/.kube/config
sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F && sudo iptables -X

# Puis rÃ©initialiser depuis le dÃ©but si nÃ©cessaire (voir section 1.5)
```

## Exercices pratiques

### Exercice 1 : DÃ©ploiement Redis
1. DÃ©ployer une instance Redis avec l'image `redis:7-alpine`
2. L'exposer via un service de type **ClusterIP** sur le port 6379
3. VÃ©rifier que le pod est en cours d'exÃ©cution

**Pourquoi ClusterIP ?** Redis est typiquement une base de donnÃ©es backend qui doit Ãªtre accessible uniquement depuis l'intÃ©rieur du cluster par d'autres applications. Il n'a pas besoin d'Ãªtre exposÃ© Ã  l'extÃ©rieur. Voir Partie 4.1 pour plus de dÃ©tails sur ClusterIP.

### Exercice 2 : Application multi-conteneurs
1. CrÃ©er un dÃ©ploiement avec 3 rÃ©plicas d'nginx
2. CrÃ©er un service **LoadBalancer**
3. Tester l'accÃ¨s Ã  l'application
4. Scaler Ã  5 rÃ©plicas
5. Observer la distribution des pods

**Ã€ propos de LoadBalancer :**
- **Avec minikube :** Le type LoadBalancer est automatiquement converti en NodePort. Pour simuler un vrai LoadBalancer localement, vous pouvez utiliser `minikube tunnel` dans un terminal sÃ©parÃ©.
- **Avec kubeadm :** Installez MetalLB pour obtenir des IPs externes pour vos LoadBalancers (voir [guide kubeadm](../docs/KUBEADM_SETUP.md#partie-6--configuration-du-loadbalancer-metallb))

### Exercice 3 : Manipulation YAML
1. CrÃ©er un fichier YAML pour dÃ©ployer MySQL
   - Image: `mysql:8.0`
   - Variables d'environnement: `MYSQL_ROOT_PASSWORD=secret`
   - Port: 3306
2. Appliquer le dÃ©ploiement
3. VÃ©rifier les logs du pod MySQL

## Solutions des exercices

<details>
<summary>Solution Exercice 1</summary>

```bash
# CrÃ©er le dÃ©ploiement
kubectl create deployment redis-demo --image=redis:7-alpine

# CrÃ©er le service
kubectl expose deployment redis-demo --type=ClusterIP --port=6379

# VÃ©rifier
kubectl get pods,services
```
</details>

<details>
<summary>Solution Exercice 2</summary>

```bash
# CrÃ©er le dÃ©ploiement
kubectl create deployment nginx-multi --image=nginx --replicas=3

# Exposer le service
kubectl expose deployment nginx-multi --type=LoadBalancer --port=80

# Obtenir l'URL
minikube service nginx-multi --url

# Scaler
kubectl scale deployment nginx-multi --replicas=5

# Observer
kubectl get pods -o wide
```
</details>

<details>
<summary>Solution Exercice 3</summary>

Fichier `mysql-deployment.yaml` :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: secret
        ports:
        - containerPort: 3306
```

Commandes :
```bash
kubectl apply -f mysql-deployment.yaml
kubectl get pods
kubectl logs <mysql-pod-name>
```
</details>

## DÃ©pannage

### ProblÃ¨me : minikube ne dÃ©marre pas
```bash
# VÃ©rifier Docker
sudo systemctl status docker

# VÃ©rifier les logs
minikube logs

# Supprimer et recrÃ©er
minikube delete
minikube start --driver=docker --force
```

### ProblÃ¨me : Impossible de se connecter au service
```bash
# VÃ©rifier que le service existe
kubectl get services

# VÃ©rifier les endpoints
kubectl get endpoints

# VÃ©rifier les pods
kubectl get pods

# Utiliser port-forward comme alternative
kubectl port-forward service/nginx-demo 8080:80
```

### ProblÃ¨me : Permission denied avec Docker
```bash
# S'assurer d'Ãªtre dans le groupe docker
sudo usermod -aG docker $USER

# Se reconnecter ou utiliser
newgrp docker
```

## Ressources complÃ©mentaires

- Documentation officielle Kubernetes : https://kubernetes.io/docs/
- Documentation minikube : https://minikube.sigs.k8s.io/docs/
- Tutoriels interactifs : https://kubernetes.io/docs/tutorials/
- Cheat sheet kubectl : https://kubernetes.io/docs/reference/kubectl/cheatsheet/

## Points clÃ©s Ã  retenir

1. **minikube** est un outil pour exÃ©cuter Kubernetes localement
2. **kubectl** est l'outil en ligne de commande pour interagir avec Kubernetes
3. Un **Deployment** gÃ¨re les rÃ©plicas de vos pods
4. Un **Service** expose vos pods au rÃ©seau
5. Les fichiers **YAML** permettent de dÃ©finir l'infrastructure as code
6. Le scaling est simple avec la commande `kubectl scale`
7. Les rollouts permettent des mises Ã  jour sans interruption
