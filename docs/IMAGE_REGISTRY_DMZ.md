# Gestion des Registres d'Images en Environnement DMZ

## Introduction

La gestion des images de conteneurs est un dÃ©fi majeur en environnement sÃ©curisÃ©. Ce document dÃ©taille les stratÃ©gies, solutions et bonnes pratiques pour gÃ©rer efficacement un registre d'images privÃ© en DMZ ou environnement isolÃ©.

## ğŸ¯ Pourquoi un Registre PrivÃ© ?

### Enjeux de SÃ©curitÃ©

En environnement sÃ©curisÃ©, l'utilisation d'un registre privÃ© est **obligatoire** pour :

1. **ContrÃ´le des images** : Seules les images validÃ©es peuvent Ãªtre dÃ©ployÃ©es
2. **Scan de vulnÃ©rabilitÃ©s** : DÃ©tection automatique des CVE
3. **ConformitÃ©** : TraÃ§abilitÃ© complÃ¨te des images utilisÃ©es
4. **Isolation** : Pas de dÃ©pendance Ã  Internet/registres publics
5. **Performance** : Cache local des images
6. **Gouvernance** : Politique de rÃ©tention et nettoyage

### Flux Typique en DMZ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Internet (Externe)                         â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Docker Hub  â”‚  â”‚     GCR      â”‚  â”‚     Quay     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    [Firewall/Proxy]
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚              â”‚  Registre Miroir    â”‚                         â”‚
â”‚              â”‚  (Zone Proxy)       â”‚                         â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                         â”‚                                     â”‚
â”‚                   [Scan/Validation]                           â”‚
â”‚                         â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚              â”‚  Registre Productionâ”‚                         â”‚
â”‚              â”‚  (Harbor/Nexus)     â”‚                         â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                         â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚      Cluster Kubernetes (DMZ)                    â”‚         â”‚
â”‚  â”‚                      â”‚                            â”‚         â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚
â”‚  â”‚  â”‚ Node1 â”‚   â”‚ Node2 â”‚   â”‚ Node3 â”‚   â”‚ Node4 â”‚ â”‚         â”‚
â”‚  â”‚  â”‚       â”‚â—„â”€â”€â”¤       â”‚â—„â”€â”€â”¤       â”‚â—„â”€â”€â”¤       â”‚ â”‚         â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
â”‚  â”‚        Pull images depuis registre privÃ©        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Solutions de Registre PrivÃ©

### Comparatif des Solutions

| CritÃ¨re | Harbor | Nexus Repository | Artifactory | Docker Registry | GitLab CR |
|---------|--------|------------------|-------------|-----------------|-----------|
| **ComplexitÃ©** | Moyenne | Moyenne | Ã‰levÃ©e | Faible | Moyenne |
| **Scan vulnÃ©rabilitÃ©s** | âœ… Trivy intÃ©grÃ© | âœ… Via plugins | âœ… Xray | âŒ Non | âœ… Via CI/CD |
| **RÃ©plication** | âœ… AvancÃ©e | âœ… Oui | âœ… Oui | âŒ Non | âœ… LimitÃ©e |
| **RBAC** | âœ… Granulaire | âœ… Granulaire | âœ… Granulaire | âŒ Basique | âœ… Oui |
| **Helm charts** | âœ… Oui | âœ… Oui | âœ… Oui | âŒ Non | âœ… Oui |
| **Proxy cache** | âœ… Oui | âœ… Oui | âœ… Oui | âŒ Non | âŒ Non |
| **Webhook** | âœ… Oui | âœ… Oui | âœ… Oui | âŒ Non | âœ… Oui |
| **API REST** | âœ… ComplÃ¨te | âœ… ComplÃ¨te | âœ… ComplÃ¨te | âš ï¸ LimitÃ©e | âœ… Oui |
| **CoÃ»t** | Gratuit (OSS) | Gratuit (OSS) | $$$ (Pro) | Gratuit | Gratuit (avec GitLab) |
| **Support** | CommunautÃ© + Pro | CommunautÃ© + Pro | Commercial | CommunautÃ© | CommunautÃ© + Enterprise |

### Recommandation par Contexte

- **Environnement Enterprise complexe** : Harbor ou Artifactory
- **Multi-format (Docker + Maven + npm)** : Nexus Repository
- **Environnement simple** : Docker Registry v2 + externe scan
- **DÃ©jÃ  GitLab** : GitLab Container Registry
- **Budget limitÃ© + besoins avancÃ©s** : Harbor (open source)

## ğŸ“¦ DÃ©ploiement de Harbor (RecommandÃ©)

### Architecture Harbor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Harbor                               â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Portal     â”‚  â”‚     Core     â”‚  â”‚   JobService â”‚      â”‚
â”‚  â”‚  (Web UI)    â”‚  â”‚   (API)      â”‚  â”‚  (Scanning)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              Nginx (Reverse Proxy)                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Registry    â”‚  â”‚  PostgreSQL  â”‚  â”‚    Redis     â”‚      â”‚
â”‚  â”‚  (Storage)   â”‚  â”‚  (Metadata)  â”‚  â”‚   (Cache)    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚     S3/      â”‚  â”‚    Trivy     â”‚  â”‚   ChartMuseumâ”‚      â”‚
â”‚  â”‚   NFS/PVC    â”‚  â”‚  (Scanner)   â”‚  â”‚  (Helm repo) â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Installation avec Helm

#### 1. PrÃ©requis

```bash
# CrÃ©er le namespace
kubectl create namespace harbor

# CrÃ©er un secret TLS
kubectl create secret tls harbor-tls \
  --cert=/path/to/cert.crt \
  --key=/path/to/cert.key \
  -n harbor

# (Optionnel) CrÃ©er un StorageClass pour persistance
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: harbor-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF
```

#### 2. Configuration Values

```yaml
# harbor-values.yaml

# Exposition du service
expose:
  type: loadBalancer
  tls:
    enabled: true
    certSource: secret
    secret:
      secretName: harbor-tls
  loadBalancer:
    name: harbor
    IP: ""  # Laissez vide pour auto-assign
    ports:
      httpPort: 80
      httpsPort: 443

# URL externe
externalURL: https://harbor.internal.company.com

# Persistance
persistence:
  enabled: true

  # Volume pour le registre
  imageChartStorage:
    type: filesystem  # ou s3, gcs, azure, etc.
    filesystem:
      rootdirectory: /storage

  persistentVolumeClaim:
    registry:
      storageClass: "harbor-storage"
      size: 500Gi
      accessMode: ReadWriteOnce

    database:
      storageClass: "harbor-storage"
      size: 10Gi
      accessMode: ReadWriteOnce

    redis:
      storageClass: "harbor-storage"
      size: 1Gi
      accessMode: ReadWriteOnce

    trivy:
      storageClass: "harbor-storage"
      size: 5Gi
      accessMode: ReadWriteOnce

# Haute disponibilitÃ©
portal:
  replicas: 2
core:
  replicas: 2
jobservice:
  replicas: 2
registry:
  replicas: 2

# Scanner de vulnÃ©rabilitÃ©s
trivy:
  enabled: true
  replicas: 1
  gitHubToken: ""  # Token pour rate limit plus Ã©levÃ©
  skipUpdate: false  # En air-gapped, mettre true

# Base de donnÃ©es
database:
  type: internal  # ou external pour DB externe
  internal:
    password: "changeme-database-password"

# Cache Redis
redis:
  type: internal
  internal:
    password: "changeme-redis-password"

# Helm Chart Repository
chartmuseum:
  enabled: true

# Notary pour signature d'images
notary:
  enabled: true

# MÃ©triques
metrics:
  enabled: true
  core:
    path: /metrics
    port: 8001
  registry:
    path: /metrics
    port: 8001
  exporter:
    path: /metrics
    port: 8001
```

#### 3. Installation

```bash
# Ajouter le repo Helm
helm repo add harbor https://helm.goharbor.io
helm repo update

# Installer Harbor
helm install harbor harbor/harbor \
  --namespace harbor \
  --create-namespace \
  -f harbor-values.yaml \
  --version 1.13.0

# VÃ©rifier le dÃ©ploiement
kubectl get pods -n harbor
kubectl get svc -n harbor

# Obtenir l'IP du LoadBalancer
kubectl get svc harbor -n harbor
```

#### 4. Configuration Post-Installation

```bash
# Se connecter Ã  Harbor
# URL: https://harbor.internal.company.com
# User: admin
# Password: Harbor12345 (par dÃ©faut, Ã  changer immÃ©diatement)

# Via CLI (installer harbor-cli)
harbor login harbor.internal.company.com \
  --username admin \
  --password Harbor12345

# CrÃ©er un projet
harbor project create \
  --name production \
  --public false

# CrÃ©er un utilisateur robot pour Kubernetes
harbor robot-account create \
  --name k8s-puller \
  --project production \
  --action pull
```

### Configuration Kubernetes pour Harbor

#### 1. CrÃ©er un Secret pour Pull Images

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: harbor-registry-secret
  namespace: production
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: <base64-encoded-docker-config>
```

Ou via CLI :
```bash
kubectl create secret docker-registry harbor-registry-secret \
  --docker-server=harbor.internal.company.com \
  --docker-username=robot$k8s-puller \
  --docker-password=<robot-token> \
  --docker-email=admin@company.com \
  -n production
```

#### 2. Utiliser le Secret dans les Pods

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      imagePullSecrets:
      - name: harbor-registry-secret
      containers:
      - name: webapp
        image: harbor.internal.company.com/production/webapp:v1.2.0
        ports:
        - containerPort: 8080
```

#### 3. Configurer un ServiceAccount par dÃ©faut

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: production
imagePullSecrets:
- name: harbor-registry-secret
```

## ğŸª Configuration du Proxy Cache et Miroir de Registries

### Concept : Pull-Through Cache

Harbor peut agir comme **proxy cache** (miroir) pour des registries externes. Quand un nÅ“ud Kubernetes demande une image, Harbor :

1. âœ… VÃ©rifie si l'image existe dans son cache local
2. âœ… Si oui, retourne l'image immÃ©diatement (rapide)
3. âœ… Si non, tÃ©lÃ©charge l'image depuis le registre externe
4. âœ… Stocke l'image en cache pour les prochaines demandes
5. âœ… Retourne l'image au client

**Avantages en DMZ** :
- Un seul point de sortie vers Internet (contrÃ´le strict du firewall)
- Cache local des images frÃ©quemment utilisÃ©es
- Ã‰conomie de bande passante
- ContinuitÃ© de service mÃªme si le registre externe est indisponible
- Scan de sÃ©curitÃ© centralisÃ©

### Architecture DÃ©taillÃ©e Proxy Cache DMZ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INTERNET (Zone Publique)                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Docker Hub  â”‚  â”‚     GCR     â”‚  â”‚    Quay     â”‚             â”‚
â”‚  â”‚ docker.io   â”‚  â”‚  gcr.io     â”‚  â”‚  quay.io    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Registries PrivÃ©s Clients                    â”‚              â”‚
â”‚  â”‚  - registry.customer-a.com                    â”‚              â”‚
â”‚  â”‚  - registry.customer-b.com                    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    [Firewall/Proxy]
                     RÃ¨gles strictes
                    (HTTPS seulement)
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ZONE DMZ (Registre Proxy)                        â”‚
â”‚                          â”‚                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚   Harbor (Proxy Cache)   â”‚                        â”‚
â”‚              â”‚  harbor.dmz.internal     â”‚                        â”‚
â”‚              â”‚                          â”‚                        â”‚
â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                        â”‚
â”‚              â”‚  â”‚  Proxy Projects   â”‚    â”‚                        â”‚
â”‚              â”‚  â”‚  - dockerhub-proxyâ”‚    â”‚                        â”‚
â”‚              â”‚  â”‚  - gcr-proxy      â”‚    â”‚                        â”‚
â”‚              â”‚  â”‚  - quay-proxy     â”‚    â”‚                        â”‚
â”‚              â”‚  â”‚  - customer-a     â”‚    â”‚                        â”‚
â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                        â”‚
â”‚              â”‚                          â”‚                        â”‚
â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                        â”‚
â”‚              â”‚  â”‚  Cache Storage   â”‚    â”‚                        â”‚
â”‚              â”‚  â”‚  (500 GB - 5 TB) â”‚    â”‚                        â”‚
â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                          â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    [Firewall Interne]
                  (Unidirectionnel: â† Pull)
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ZONE INTERNE (Clusters Kubernetes)                       â”‚
â”‚                          â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Cluster 1 (Production)                                â”‚   â”‚
â”‚  â”‚                       â”‚                                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚  â”‚Node1â”‚  â”‚Node2â”‚   â”‚Node3â”‚   â”‚Node4â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚     â”‚â—„â”€â”¤     â”‚â—„â”€â”€â”¤     â”‚â—„â”€â”€â”¤     â”‚                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â”‚             Pull depuis:                                 â”‚   â”‚
â”‚  â”‚             harbor.dmz.internal/dockerhub-proxy/nginx    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Cluster 2 (DÃ©veloppement)                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”                                        â”‚   â”‚
â”‚  â”‚  â”‚Node1â”‚  â”‚Node2â”‚                                        â”‚   â”‚
â”‚  â”‚  â”‚     â”‚â—„â”€â”¤     â”‚                                        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration des Endpoints de Registries Externes

#### 1. CrÃ©er les Registry Endpoints dans Harbor

##### A. Docker Hub (Registre Public)

Via l'interface Harbor :
1. **Registrations** > **New Endpoint**
2. ParamÃ¨tres :
   - **Provider** : Docker Hub
   - **Name** : dockerhub
   - **Endpoint URL** : https://hub.docker.com
   - **Access ID** : (optionnel, pour augmenter le rate limit)
   - **Access Secret** : (optionnel)
   - **Verify Remote Cert** : âœ… Oui

Via API :
```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "dockerhub",
    "type": "docker-hub",
    "url": "https://hub.docker.com",
    "credential": {
      "access_key": "your-dockerhub-username",
      "access_secret": "your-dockerhub-token"
    },
    "insecure": false
  }'
```

##### B. Google Container Registry (GCR)

```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "gcr",
    "type": "google-gcr",
    "url": "https://gcr.io",
    "credential": {
      "access_key": "_json_key",
      "access_secret": "{\"type\":\"service_account\",\"project_id\":\"...\",\"private_key_id\":\"...\",\"private_key\":\"...\"}"
    },
    "insecure": false
  }'
```

##### C. Quay.io

```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "quay",
    "type": "quay",
    "url": "https://quay.io",
    "credential": {
      "access_key": "your-quay-username",
      "access_secret": "your-quay-token"
    },
    "insecure": false
  }'
```

##### D. Registre PrivÃ© Client (avec authentification)

```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "customer-a-registry",
    "type": "docker-registry",
    "url": "https://registry.customer-a.com",
    "credential": {
      "access_key": "robot-account-user",
      "access_secret": "robot-account-token"
    },
    "insecure": false
  }'
```

##### E. Amazon ECR

```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "aws-ecr",
    "type": "aws-ecr",
    "url": "https://123456789012.dkr.ecr.eu-west-1.amazonaws.com",
    "credential": {
      "access_key": "AKIA...",
      "access_secret": "wJalrXUtn..."
    },
    "insecure": false
  }'
```

##### F. Azure Container Registry (ACR)

```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/registries" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "azure-acr",
    "type": "azure-acr",
    "url": "https://myregistry.azurecr.io",
    "credential": {
      "access_key": "service-principal-id",
      "access_secret": "service-principal-password"
    },
    "insecure": false
  }'
```

#### 2. CrÃ©er des Proxy Projects

Un **Proxy Project** dans Harbor est un projet spÃ©cial qui cache automatiquement les images d'un registre externe.

##### A. CrÃ©er un Proxy Project pour Docker Hub

Via l'interface Harbor :
1. **Projects** > **New Project**
2. ParamÃ¨tres :
   - **Project Name** : dockerhub-proxy
   - **Access Level** : Private
   - **Proxy Cache** : âœ… ActivÃ©
   - **Registry** : dockerhub (endpoint crÃ©Ã© prÃ©cÃ©demment)

Via API :
```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/projects" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "project_name": "dockerhub-proxy",
    "public": false,
    "registry_id": 1
  }'
```

##### B. CrÃ©er plusieurs Proxy Projects

```bash
# GCR Proxy
curl -X POST "https://harbor.dmz.internal/api/v2.0/projects" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "project_name": "gcr-proxy",
    "public": false,
    "registry_id": 2
  }'

# Quay Proxy
curl -X POST "https://harbor.dmz.internal/api/v2.0/projects" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "project_name": "quay-proxy",
    "public": false,
    "registry_id": 3
  }'

# Customer A Proxy
curl -X POST "https://harbor.dmz.internal/api/v2.0/projects" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "project_name": "customer-a-proxy",
    "public": false,
    "registry_id": 4
  }'
```

### Utilisation du Proxy Cache depuis Kubernetes

#### 1. Adaptation des Image Names

**Format original** â†’ **Format avec proxy cache**

| Registre Source | Image Originale | Image via Harbor Proxy |
|-----------------|-----------------|------------------------|
| **Docker Hub** | `nginx:latest` | `harbor.dmz.internal/dockerhub-proxy/library/nginx:latest` |
| **Docker Hub** | `redis:7-alpine` | `harbor.dmz.internal/dockerhub-proxy/library/redis:7-alpine` |
| **Docker Hub** | `grafana/grafana:latest` | `harbor.dmz.internal/dockerhub-proxy/grafana/grafana:latest` |
| **GCR** | `gcr.io/google-containers/pause:3.9` | `harbor.dmz.internal/gcr-proxy/google-containers/pause:3.9` |
| **Quay** | `quay.io/prometheus/prometheus:v2.45.0` | `harbor.dmz.internal/quay-proxy/prometheus/prometheus:v2.45.0` |
| **Customer A** | `registry.customer-a.com/app/backend:v1.0` | `harbor.dmz.internal/customer-a-proxy/app/backend:v1.0` |

**RÃ¨gle de transformation** :
```
<original-registry>/<namespace>/<image>:<tag>
                â†“
harbor.dmz.internal/<proxy-project>/<namespace>/<image>:<tag>
```

**Note importante pour Docker Hub** :
- Images officielles comme `nginx`, `redis`, `postgres` sont dans le namespace `library`
- Donc `nginx:latest` devient `harbor.dmz.internal/dockerhub-proxy/library/nginx:latest`

#### 2. Exemple de Deployment avec Proxy Cache

##### Avant (accÃ¨s direct Ã  Internet)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: nginx
        image: nginx:1.25-alpine
      - name: redis
        image: redis:7-alpine
```

##### AprÃ¨s (via Harbor Proxy Cache en DMZ)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      # Secret pour s'authentifier au registre Harbor
      imagePullSecrets:
      - name: harbor-registry-secret

      containers:
      - name: nginx
        # Image rÃ©cupÃ©rÃ©e via proxy cache Harbor
        image: harbor.dmz.internal/dockerhub-proxy/library/nginx:1.25-alpine

      - name: redis
        # Image rÃ©cupÃ©rÃ©e via proxy cache Harbor
        image: harbor.dmz.internal/dockerhub-proxy/library/redis:7-alpine
```

#### 3. Exemples AvancÃ©s

##### A. Application Multi-Registres

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: monitoring-stack
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: monitoring
  template:
    metadata:
      labels:
        app: monitoring
    spec:
      imagePullSecrets:
      - name: harbor-registry-secret

      containers:
      # Prometheus depuis Quay.io
      - name: prometheus
        image: harbor.dmz.internal/quay-proxy/prometheus/prometheus:v2.45.0
        ports:
        - containerPort: 9090

      # Grafana depuis Docker Hub
      - name: grafana
        image: harbor.dmz.internal/dockerhub-proxy/grafana/grafana:10.0.0
        ports:
        - containerPort: 3000

      # Application custom depuis registre client
      - name: custom-exporter
        image: harbor.dmz.internal/customer-a-proxy/monitoring/exporter:v1.2.0
        ports:
        - containerPort: 8080
```

##### B. Job avec Image GCR

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: data-migration
  namespace: production
spec:
  template:
    spec:
      imagePullSecrets:
      - name: harbor-registry-secret

      restartPolicy: Never
      containers:
      - name: migrator
        # Image Google Cloud depuis GCR via Harbor proxy
        image: harbor.dmz.internal/gcr-proxy/google-samples/hello-app:1.0
        command: ["./migrate"]
```

##### C. DaemonSet avec Image AWS ECR

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: log-collector
  template:
    metadata:
      labels:
        app: log-collector
    spec:
      imagePullSecrets:
      - name: harbor-registry-secret

      containers:
      - name: fluentd
        # Image depuis AWS ECR via Harbor proxy
        image: harbor.dmz.internal/aws-ecr-proxy/logging/fluentd:v1.16
        volumeMounts:
        - name: varlog
          mountPath: /var/log

      volumes:
      - name: varlog
        hostPath:
          path: /var/log
```

### PrÃ©chargement d'Images (Preheat)

En DMZ stricte, il peut Ãªtre nÃ©cessaire de **prÃ©charger les images** dans Harbor avant le dÃ©ploiement.

#### MÃ©thode 1 : Pull Manuel via Script

```bash
#!/bin/bash
# preheat-images.sh - Script pour prÃ©charger des images dans Harbor

HARBOR_URL="harbor.dmz.internal"
HARBOR_USER="admin"
HARBOR_PASSWORD="Harbor12345"

# Liste des images Ã  prÃ©charger
IMAGES=(
  "dockerhub-proxy/library/nginx:1.25-alpine"
  "dockerhub-proxy/library/redis:7-alpine"
  "dockerhub-proxy/grafana/grafana:10.0.0"
  "quay-proxy/prometheus/prometheus:v2.45.0"
  "gcr-proxy/google-samples/hello-app:1.0"
)

# Login Ã  Harbor
echo "$HARBOR_PASSWORD" | docker login $HARBOR_URL -u $HARBOR_USER --password-stdin

# PrÃ©charger chaque image
for IMAGE in "${IMAGES[@]}"; do
  echo "============================================"
  echo "Pulling: ${HARBOR_URL}/${IMAGE}"
  echo "============================================"

  docker pull ${HARBOR_URL}/${IMAGE}

  if [ $? -eq 0 ]; then
    echo "âœ… Successfully pulled: ${IMAGE}"
  else
    echo "âŒ Failed to pull: ${IMAGE}"
    exit 1
  fi
done

echo ""
echo "============================================"
echo "âœ… All images preheated successfully!"
echo "============================================"

# Nettoyer les images locales
docker image prune -f
```

#### MÃ©thode 2 : Preheat Policy (Harbor 2.6+)

Harbor 2.6+ offre une fonctionnalitÃ© de **preheat policy** pour automatiser le prÃ©chargement.

Via l'interface Harbor :
1. **Projects** > SÃ©lectionner le proxy project
2. **P2P Preheat** > **New Policy**
3. Configurer :
   - **Name** : preheat-critical-images
   - **Trigger Type** : Manual ou Scheduled
   - **Filters** : Par tag ou nom d'image
   - **Provider** : Dragonfly ou Kraken (P2P distribution)

Via API :
```bash
curl -X POST "https://harbor.dmz.internal/api/v2.0/projects/dockerhub-proxy/preheat/policies" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "name": "preheat-critical-images",
    "description": "Preheat critical images for production",
    "filters": [
      {
        "type": "repository",
        "value": "library/nginx"
      },
      {
        "type": "tag",
        "value": "1.**"
      }
    ],
    "trigger": {
      "type": "manual"
    },
    "enabled": true
  }'
```

#### MÃ©thode 3 : Import/Export d'Images (Air-Gapped)

Pour environnements **complÃ¨tement isolÃ©s** (air-gapped), utiliser l'export/import manuel.

```bash
# Sur une machine avec accÃ¨s Internet
# ===================================

# 1. TÃ©lÃ©charger les images
docker pull nginx:1.25-alpine
docker pull redis:7-alpine
docker pull grafana/grafana:10.0.0

# 2. Sauvegarder les images dans un tar
docker save -o images-bundle.tar \
  nginx:1.25-alpine \
  redis:7-alpine \
  grafana/grafana:10.0.0

# 3. TransfÃ©rer images-bundle.tar vers la DMZ (clÃ© USB, transfert sÃ©curisÃ©, etc.)

# Sur la machine Harbor en DMZ
# ============================

# 4. Charger les images
docker load -i images-bundle.tar

# 5. Re-tagger avec le namespace Harbor
docker tag nginx:1.25-alpine harbor.dmz.internal/dockerhub-proxy/library/nginx:1.25-alpine
docker tag redis:7-alpine harbor.dmz.internal/dockerhub-proxy/library/redis:7-alpine
docker tag grafana/grafana:10.0.0 harbor.dmz.internal/dockerhub-proxy/grafana/grafana:10.0.0

# 6. Login Ã  Harbor
docker login harbor.dmz.internal -u admin

# 7. Push vers Harbor
docker push harbor.dmz.internal/dockerhub-proxy/library/nginx:1.25-alpine
docker push harbor.dmz.internal/dockerhub-proxy/library/redis:7-alpine
docker push harbor.dmz.internal/dockerhub-proxy/grafana/grafana:10.0.0
```

### Automatisation avec Script Python

```python
#!/usr/bin/env python3
"""
Harbor Proxy Cache Manager
Automatise le prÃ©chargement d'images via Harbor proxy cache
"""

import requests
import json
from typing import List, Dict

class HarborProxyManager:
    def __init__(self, harbor_url: str, username: str, password: str):
        self.harbor_url = harbor_url.rstrip('/')
        self.auth = (username, password)
        self.session = requests.Session()
        self.session.auth = self.auth

    def create_registry_endpoint(self, name: str, registry_type: str,
                                 url: str, access_key: str = None,
                                 access_secret: str = None) -> Dict:
        """CrÃ©er un endpoint de registre externe"""
        endpoint = f"{self.harbor_url}/api/v2.0/registries"

        data = {
            "name": name,
            "type": registry_type,
            "url": url,
            "insecure": False
        }

        if access_key and access_secret:
            data["credential"] = {
                "access_key": access_key,
                "access_secret": access_secret
            }

        response = self.session.post(endpoint, json=data)
        response.raise_for_status()
        return response.json()

    def create_proxy_project(self, project_name: str, registry_id: int) -> Dict:
        """CrÃ©er un projet proxy cache"""
        endpoint = f"{self.harbor_url}/api/v2.0/projects"

        data = {
            "project_name": project_name,
            "public": False,
            "registry_id": registry_id
        }

        response = self.session.post(endpoint, json=data)
        response.raise_for_status()
        return response.json()

    def preheat_images(self, proxy_project: str, images: List[str]) -> None:
        """PrÃ©charger une liste d'images via le proxy cache"""
        import docker
        client = docker.from_env()

        # Login Ã  Harbor
        client.login(
            username=self.auth[0],
            password=self.auth[1],
            registry=self.harbor_url.replace('https://', '')
        )

        for image in images:
            full_image = f"{self.harbor_url.replace('https://', '')}/{proxy_project}/{image}"
            print(f"Pulling {full_image}...")

            try:
                client.images.pull(full_image)
                print(f"âœ… {image} preheated successfully")
            except Exception as e:
                print(f"âŒ Failed to preheat {image}: {e}")

# Utilisation
if __name__ == "__main__":
    manager = HarborProxyManager(
        harbor_url="https://harbor.dmz.internal",
        username="admin",
        password="Harbor12345"
    )

    # CrÃ©er un endpoint Docker Hub
    registry_id = manager.create_registry_endpoint(
        name="dockerhub",
        registry_type="docker-hub",
        url="https://hub.docker.com"
    )

    # CrÃ©er un projet proxy
    manager.create_proxy_project(
        project_name="dockerhub-proxy",
        registry_id=registry_id
    )

    # PrÃ©charger des images critiques
    images_to_preheat = [
        "library/nginx:1.25-alpine",
        "library/redis:7-alpine",
        "grafana/grafana:10.0.0"
    ]

    manager.preheat_images("dockerhub-proxy", images_to_preheat)
```

### Monitoring du Proxy Cache

#### MÃ©triques Importantes

```promql
# Taux de cache hit (images servies depuis le cache)
rate(harbor_proxy_cache_hit_total[5m])

# Taux de cache miss (images tÃ©lÃ©chargÃ©es depuis l'externe)
rate(harbor_proxy_cache_miss_total[5m])

# Temps de rÃ©ponse du proxy cache
histogram_quantile(0.95, rate(harbor_proxy_request_duration_seconds_bucket[5m]))

# Espace utilisÃ© par projet proxy
harbor_project_quota_usage_byte{project_name=~".*-proxy"}

# Nombre d'images dans les projets proxy
harbor_project_repo_count{project_name=~".*-proxy"}
```

#### Dashboard Grafana pour Proxy Cache

```json
{
  "dashboard": {
    "title": "Harbor Proxy Cache Monitoring",
    "panels": [
      {
        "title": "Cache Hit Rate",
        "targets": [
          {
            "expr": "rate(harbor_proxy_cache_hit_total[5m]) / (rate(harbor_proxy_cache_hit_total[5m]) + rate(harbor_proxy_cache_miss_total[5m])) * 100"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Cache Storage Usage",
        "targets": [
          {
            "expr": "harbor_project_quota_usage_byte{project_name=~\".*-proxy\"}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Top Pulled Images",
        "targets": [
          {
            "expr": "topk(10, rate(harbor_proxy_pull_count[1h]))"
          }
        ],
        "type": "table"
      }
    ]
  }
}
```

### Troubleshooting Proxy Cache

#### ProblÃ¨me 1 : Images ne se cachent pas

```bash
# VÃ©rifier que le projet est bien configurÃ© en mode proxy
curl -u "admin:Harbor12345" \
  "https://harbor.dmz.internal/api/v2.0/projects/dockerhub-proxy" | jq

# Doit contenir : "registry_id": <number>

# VÃ©rifier l'endpoint du registre
curl -u "admin:Harbor12345" \
  "https://harbor.dmz.internal/api/v2.0/registries" | jq

# Tester la connectivitÃ© vers le registre externe
curl -u "admin:Harbor12345" \
  -X POST "https://harbor.dmz.internal/api/v2.0/registries/ping" \
  -d '{"id": 1}'
```

#### ProblÃ¨me 2 : Erreur d'authentification

```bash
# VÃ©rifier les credentials du registre externe
curl -u "admin:Harbor12345" \
  "https://harbor.dmz.internal/api/v2.0/registries/<registry-id>" | jq '.credential'

# Re-tester les credentials
docker login hub.docker.com -u <username> -p <token>
```

#### ProblÃ¨me 3 : Firewall bloque l'accÃ¨s externe

```bash
# Tester la connectivitÃ© depuis Harbor vers l'externe
kubectl exec -it <harbor-registry-pod> -n harbor -- sh

# Depuis le pod Harbor
wget -O- https://hub.docker.com/v2/
wget -O- https://gcr.io/v2/

# Si Ã©chec, configurer le proxy HTTP dans Harbor
```

Configuration proxy HTTP dans Harbor :
```yaml
# Dans harbor-values.yaml
proxy:
  httpProxy: "http://proxy.company.com:8080"
  httpsProxy: "http://proxy.company.com:8080"
  noProxy: "127.0.0.1,localhost,harbor.dmz.internal"
```

## ğŸ” Scan de VulnÃ©rabilitÃ©s

### Configuration Trivy dans Harbor

#### 1. Politique de Scan Automatique

Via l'interface Harbor :
- **Configuration** > **Interrogation**
- CrÃ©er une nouvelle politique :
  - Scan automatique Ã  chaque push
  - Bloquer le dÃ©ploiement si vulnÃ©rabilitÃ©s CRITICAL/HIGH

#### 2. IntÃ©gration CI/CD

```yaml
# .gitlab-ci.yml
stages:
  - build
  - scan
  - deploy

variables:
  HARBOR_URL: "harbor.internal.company.com"
  HARBOR_PROJECT: "production"
  IMAGE_NAME: "${HARBOR_URL}/${HARBOR_PROJECT}/webapp"
  IMAGE_TAG: "${CI_COMMIT_SHORT_SHA}"

build-image:
  stage: build
  script:
    - docker build -t ${IMAGE_NAME}:${IMAGE_TAG} .
    - docker login -u $HARBOR_USER -p $HARBOR_PASSWORD ${HARBOR_URL}
    - docker push ${IMAGE_NAME}:${IMAGE_TAG}

scan-image:
  stage: scan
  script:
    # Attendre que Harbor scanne l'image
    - sleep 30

    # VÃ©rifier le rÃ©sultat du scan via API Harbor
    - |
      SCAN_RESULT=$(curl -s -u "${HARBOR_USER}:${HARBOR_PASSWORD}" \
        "https://${HARBOR_URL}/api/v2.0/projects/${HARBOR_PROJECT}/repositories/webapp/artifacts/${IMAGE_TAG}/additions/vulnerabilities")

      CRITICAL=$(echo $SCAN_RESULT | jq '.scan_overview.severity.Critical // 0')
      HIGH=$(echo $SCAN_RESULT | jq '.scan_overview.severity.High // 0')

      if [ "$CRITICAL" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
        echo "âŒ Image has $CRITICAL critical and $HIGH high vulnerabilities"
        exit 1
      fi

      echo "âœ… Image passed security scan"

deploy:
  stage: deploy
  script:
    - kubectl set image deployment/webapp webapp=${IMAGE_NAME}:${IMAGE_TAG} -n production
  only:
    - main
```

### Scan Manuel avec Trivy

```bash
# Scanner une image locale
trivy image harbor.internal.company.com/production/webapp:v1.2.0

# Scanner et gÃ©nÃ©rer un rapport JSON
trivy image -f json -o report.json \
  harbor.internal.company.com/production/webapp:v1.2.0

# Scanner uniquement les vulnÃ©rabilitÃ©s critiques et hautes
trivy image --severity CRITICAL,HIGH \
  harbor.internal.company.com/production/webapp:v1.2.0

# Ignorer les vulnÃ©rabilitÃ©s non fixÃ©es
trivy image --ignore-unfixed \
  harbor.internal.company.com/production/webapp:v1.2.0
```

## ğŸ”„ Gestion du Cycle de Vie des Images

### Politique de RÃ©tention

```yaml
# Configuration dans Harbor UI
# Project > Tag Retention

# Exemple de rÃ¨gle :
# - Garder les 10 derniÃ¨res images taggÃ©es
# - Garder les images des 30 derniers jours
# - Supprimer automatiquement les images non taggÃ©es
# - Garder indÃ©finiment les images en production

# Via API
curl -X POST "https://harbor.internal.company.com/api/v2.0/retentions" \
  -H "Content-Type: application/json" \
  -u "admin:Harbor12345" \
  -d '{
    "scope": {
      "level": "project",
      "ref": 1
    },
    "trigger": {
      "kind": "Schedule",
      "settings": {
        "cron": "0 0 * * 0"
      }
    },
    "rules": [
      {
        "disabled": false,
        "action": "retain",
        "params": {
          "latestPushedK": 10
        },
        "tag_selectors": [
          {
            "kind": "doublestar",
            "decoration": "matches",
            "pattern": "**"
          }
        ],
        "scope_selectors": {
          "repository": [
            {
              "kind": "doublestar",
              "decoration": "matches",
              "pattern": "**"
            }
          ]
        }
      }
    ]
  }'
```

### StratÃ©gie de Tagging

#### Convention de Nommage

```bash
# Format recommandÃ© :
# <registre>/<projet>/<image>:<tag>

# Exemples :
harbor.internal.company.com/production/webapp:v1.2.0
harbor.internal.company.com/production/webapp:v1.2.0-sha-a1b2c3d
harbor.internal.company.com/production/webapp:latest
harbor.internal.company.com/production/webapp:main-20250115-1430

# Tags Ã  Ã©viter en production :
# - latest (ambigu, non versionnÃ©)
# - dev, test (environnement, pas version)
```

#### Multi-Tagging

```bash
# Builder et pousser avec plusieurs tags
docker build -t webapp:${VERSION} .

# Tag sÃ©mantique
docker tag webapp:${VERSION} \
  harbor.internal.company.com/production/webapp:${VERSION}

# Tag avec commit SHA
docker tag webapp:${VERSION} \
  harbor.internal.company.com/production/webapp:${VERSION}-${GIT_SHA}

# Tag latest (pour env dev seulement)
docker tag webapp:${VERSION} \
  harbor.internal.company.com/dev/webapp:latest

# Pousser tous les tags
docker push harbor.internal.company.com/production/webapp --all-tags
```

### RÃ©plication Multi-Site

#### Configuration de la RÃ©plication Harbor

```yaml
# Harbor permet la rÃ©plication entre instances

# Source: Harbor Paris
# Target: Harbor Lyon (DR)

# Via Harbor UI:
# Administration > Replications > New Replication Rule

# - Name: paris-to-lyon-production
# - Source registry: Local
# - Source resources filter:
#   - Name: production/**
#   - Tag: v*
# - Destination:
#   - Provider: Harbor
#   - Endpoint: https://harbor-lyon.internal.company.com
#   - Access ID: replication-user
#   - Access secret: ***
# - Trigger Mode: Event Based (on push)
# - Override: true
# - Enable rule: true
```

Via API :
```bash
curl -X POST "https://harbor-paris.internal.company.com/api/v2.0/replication/policies" \
  -H "Content-Type: application/json" \
  -u "admin:password" \
  -d '{
    "name": "paris-to-lyon-production",
    "src_registry": {
      "id": 0
    },
    "dest_registry": {
      "id": 1
    },
    "dest_namespace": "production",
    "trigger": {
      "type": "event_based"
    },
    "filters": [
      {
        "type": "name",
        "value": "production/**"
      },
      {
        "type": "tag",
        "value": "v*"
      }
    ],
    "deletion": false,
    "override": true,
    "enabled": true
  }'
```

## ğŸ” SÃ©curitÃ© AvancÃ©e

### Signature d'Images avec Notary

#### 1. Activer Content Trust

```bash
# CÃ´tÃ© client
export DOCKER_CONTENT_TRUST=1
export DOCKER_CONTENT_TRUST_SERVER=https://harbor.internal.company.com:4443

# Pousser une image signÃ©e
docker push harbor.internal.company.com/production/webapp:v1.2.0
# La signature est automatiquement crÃ©Ã©e
```

#### 2. VÃ©rification des Signatures

```yaml
# Utiliser un admission controller pour vÃ©rifier les signatures

# Option 1: Portieris (IBM)
apiVersion: portieris.cloud.ibm.com/v1
kind: ImagePolicy
metadata:
  name: production-policy
  namespace: production
spec:
  repositories:
  - name: "harbor.internal.company.com/production/*"
    policy:
      trust:
        enabled: true
        trustServer: "https://harbor.internal.company.com:4443"
      va:
        enabled: true

# Option 2: Connaisseur
apiVersion: v1
kind: ConfigMap
metadata:
  name: connaisseur-config
  namespace: connaisseur
data:
  config.yaml: |
    policy:
      - pattern: "harbor.internal.company.com/production/*:*"
        validator: notary
        with:
          trust_roots:
          - name: default
            key: |
              -----BEGIN PUBLIC KEY-----
              ...
              -----END PUBLIC KEY-----
```

### RBAC Granulaire dans Harbor

```bash
# CrÃ©er un projet avec permissions fines
# Via Harbor UI: Projects > New Project

# RÃ´les disponibles:
# - Project Admin: Gestion complÃ¨te
# - Master: Push/Pull + scan
# - Developer: Push/Pull
# - Guest: Pull seulement
# - Limited Guest: Pull artifacts listÃ©s seulement

# Ajouter un membre
curl -X POST "https://harbor.internal.company.com/api/v2.0/projects/production/members" \
  -H "Content-Type: application/json" \
  -u "admin:password" \
  -d '{
    "role_id": 2,
    "member_user": {
      "username": "developer-team"
    }
  }'

# CrÃ©er un robot account avec permissions limitÃ©es
curl -X POST "https://harbor.internal.company.com/api/v2.0/robots" \
  -H "Content-Type: application/json" \
  -u "admin:password" \
  -d '{
    "name": "ci-builder",
    "description": "Robot account for CI/CD",
    "duration": -1,
    "level": "project",
    "permissions": [
      {
        "kind": "project",
        "namespace": "production",
        "access": [
          {
            "resource": "repository",
            "action": "push"
          },
          {
            "resource": "repository",
            "action": "pull"
          }
        ]
      }
    ]
  }'
```

## ğŸ“Š Monitoring et MÃ©triques

### Prometheus Metrics

```yaml
# ServiceMonitor pour Harbor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: harbor-metrics
  namespace: harbor
  labels:
    app: harbor
spec:
  selector:
    matchLabels:
      app: harbor
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### MÃ©triques Importantes Ã  Surveiller

```promql
# Nombre de pulls d'images
rate(harbor_project_artifact_pull_count[5m])

# Espace disque utilisÃ©
harbor_project_quota_usage_byte / harbor_project_quota_hard_byte * 100

# DurÃ©e des scans
harbor_scan_duration_seconds

# Nombre de vulnÃ©rabilitÃ©s par projet
sum by (project_name, severity) (harbor_artifact_vulnerabilities)

# Taux d'erreur API
rate(harbor_api_request_total{code=~"5.."}[5m])
```

### Alerting

```yaml
# PrometheusRule pour alertes Harbor
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: harbor-alerts
  namespace: harbor
spec:
  groups:
  - name: harbor
    interval: 30s
    rules:
    - alert: HarborHighVulnerabilities
      expr: |
        sum by (project_name) (
          harbor_artifact_vulnerabilities{severity="Critical"}
        ) > 5
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Harbor project {{ $labels.project_name }} has critical vulnerabilities"
        description: "{{ $value }} critical vulnerabilities detected"

    - alert: HarborDiskSpaceHigh
      expr: |
        harbor_project_quota_usage_byte / harbor_project_quota_hard_byte > 0.85
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Harbor project quota almost full"
        description: "Project {{ $labels.project_name }} is using {{ $value | humanizePercentage }} of quota"

    - alert: HarborAPIErrors
      expr: |
        rate(harbor_api_request_total{code=~"5.."}[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High rate of Harbor API errors"
        description: "{{ $value }} errors per second"
```

## ğŸ“š Bonnes Pratiques

### DO âœ…

- Utiliser des tags sÃ©mantiques (v1.2.3, pas latest en prod)
- Activer le scan automatique de vulnÃ©rabilitÃ©s
- Configurer une politique de rÃ©tention
- Utiliser des robot accounts pour l'automatisation
- Activer la rÃ©plication pour DR
- Monitorer l'espace disque
- Faire des backups rÃ©guliers de la base de donnÃ©es Harbor
- Utiliser TLS pour toutes les communications
- ImplÃ©menter le RBAC granulaire

### DON'T âŒ

- Utiliser latest en production
- DÃ©sactiver le scan de vulnÃ©rabilitÃ©s
- Donner des permissions admin Ã  tous
- Oublier de configurer la rÃ©tention (explosion du stockage)
- Utiliser le compte admin pour les dÃ©ploiements automatisÃ©s
- Ignorer les alertes de vulnÃ©rabilitÃ©s
- Oublier de monitorer l'usage du stockage
- Utiliser HTTP (non chiffrÃ©)

## ğŸ”— RÃ©fÃ©rences

- [Harbor Documentation](https://goharbor.io/docs/)
- [Harbor API Reference](https://goharbor.io/docs/latest/working-with-projects/working-with-images/pulling-pushing-images/)
- [Trivy Documentation](https://aquasecurity.github.io/trivy/)
- [Notary Documentation](https://github.com/notaryproject/notary)
- [OCI Distribution Spec](https://github.com/opencontainers/distribution-spec)

## Articles ComplÃ©mentaires

- [Gestion de Cluster SÃ©curisÃ©](SECURE_CLUSTER_MANAGEMENT.md)
- [Cycle de Vie des Applications](APPLICATION_LIFECYCLE.md)
- [DÃ©ploiement Air-Gapped](AIRGAP_DEPLOYMENT.md)
